{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the necessary imports\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                    text  sentiment\n",
       " 0      I absolutely hate this programme, what kind of...          0\n",
       " 1      Bill Paxton, of Aliens, Near Dark, and Termina...          1\n",
       " 2      Let me start by saying at the young age of 34 ...          1\n",
       " 3      Tashan - the title itself explains the nature ...          0\n",
       " 4      While this movie won't go down in the annals o...          1\n",
       " 5      Living in the Middle East (in Israel), I was e...          0\n",
       " 6      The first half hour or so of this movie I like...          0\n",
       " 7      I haven't actually finished the film. You may ...          0\n",
       " 8      I agree with another user here and have to say...          1\n",
       " 9      Cinematically, this film stinks. So does a lot...          1\n",
       " 10     My husband is a huge Robin Williams fan. I lik...          0\n",
       " 11     I wouldn't recommend this unless you're keen o...          0\n",
       " 12     Robert Taylor definitely showed himself to be ...          0\n",
       " 13     Considering that I felt like picking up a new ...          0\n",
       " 14     I missed the beginning but I did see most of i...          0\n",
       " 15     I'm not going to bother with a plot synopsis s...          0\n",
       " 16     I read somewhere that when Kay Francis refused...          0\n",
       " 17     The only good thing about \"People I Know\" is t...          0\n",
       " 18     This romantic comedy isn't too bad. There are ...          0\n",
       " 19     This is sad this movie is the tops this should...          1\n",
       " 20     I don't remember when I first heard about this...          1\n",
       " 21     This is one of the best animated movies I've e...          1\n",
       " 22     This movie set out to be better than the avera...          1\n",
       " 23     This film so NOT funny - such a waste of great...          0\n",
       " 24     Eddie Murphy spends his time looking for lost ...          1\n",
       " 25     How sad to see the beautiful and talented Tina...          0\n",
       " 26     This movie is one among the very few Indian mo...          1\n",
       " 27     Alex D. Linz replaces Macaulay Culkin as the c...          0\n",
       " 28     Quite possibly the worst movie that I have eve...          0\n",
       " 29     I went to see this movie with a crowd that con...          0\n",
       " ...                                                  ...        ...\n",
       " 24970  We don't have to lose this movie, this is one ...          1\n",
       " 24971  \"The Straight Story\" is a truly beautiful movi...          1\n",
       " 24972  This is my first comment on IMDb website, and ...          1\n",
       " 24973  Both Robert Duvall and Glenn Close played thei...          1\n",
       " 24974  This game is amazing. Really, you should get i...          1\n",
       " 24975  this film was shrouded in scandal for so long ...          0\n",
       " 24976  With the MASSIVE advertising this is getting o...          0\n",
       " 24977  German private TV is ill-renowned for copying ...          1\n",
       " 24978  ...said a couple exiting the movie theater jus...          0\n",
       " 24979  Having been pleasantly surprised by Sandra Bul...          0\n",
       " 24980  Although it really isn't such a terribly movie...          0\n",
       " 24981  I tuned into this thing one night on a cable c...          0\n",
       " 24982  I really enjoyed The 60's. Not being of that g...          1\n",
       " 24983  Oh man is this movie bad. It flows horribly. T...          0\n",
       " 24984  This movie is probably the worst I have seen. ...          0\n",
       " 24985  I first saw this movie in a theater in France ...          1\n",
       " 24986  Suraj Barjatya is best in movies on marriage. ...          1\n",
       " 24987  I just watched this film 15 minutes ago, and I...          0\n",
       " 24988  and rent a GOOD horror movie. It's like the wr...          0\n",
       " 24989  Frankly I'm rather incensed that on the basis ...          0\n",
       " 24990  I have grown up reading Modesty Blaise, both t...          0\n",
       " 24991  I was not nearly as smitten with this as many ...          0\n",
       " 24992  About the only thing I liked about this film i...          0\n",
       " 24993  Oh my God what the hell happened here?!! I'm n...          0\n",
       " 24994  This masterpiece of lesbian horror comes from ...          1\n",
       " 24995  If you want to see a mystery, don't watch this...          0\n",
       " 24996  This movie is like the material S.E. Hinton wa...          0\n",
       " 24997  i think this one sucked on ice, because it lef...          0\n",
       " 24998  Billy Wilder is co-credited for the story, and...          1\n",
       " 24999  \"They All Laughed\" is one of those little movi...          1\n",
       " \n",
       " [25000 rows x 2 columns],\n",
       "                                                     text  sentiment\n",
       " 0      Tumbling Doll of Flesh (aka Niku daruma and Ps...          1\n",
       " 1      This is a quiet movie. It's a simple story abo...          1\n",
       " 2      Okay, I'll admit right up front that the Inki ...          1\n",
       " 3      In my opinion this is the best Oliver Stone fl...          1\n",
       " 4      This Bravo special is one of the most purely e...          1\n",
       " 5      The title of this documentary is very misleadi...          0\n",
       " 6      Contains Major Spoilers, on the off chance you...          0\n",
       " 7      I first saw The Buddy Holly Story when I was a...          1\n",
       " 8      It is a rare and fine spectacle, an allegory o...          1\n",
       " 9      I saw this film as a sneak preview before the ...          0\n",
       " 10     I've come to realise through watching this sor...          0\n",
       " 11     This was intolerable. (SPOILER #1) Protagonist...          0\n",
       " 12     I know Jesse Franco is responsible for a wide ...          0\n",
       " 13     A nice, humorous mix of music hall (in the fir...          1\n",
       " 14     The Movie is not bad in itself...till you see ...          0\n",
       " 15     In 1976 a mother named Norma Lewis (Cameron Di...          0\n",
       " 16     When i first saw this show advertised to be on...          1\n",
       " 17     Once again John Madden has given us a magnific...          1\n",
       " 18     The second in director Cohen's trilogy of Seco...          1\n",
       " 19     This movie was a modern day scarface.It had me...          1\n",
       " 20     No idea how this is rated as high as it is (5....          0\n",
       " 21     Once again, Bugs Bunny sacred home is violated...          1\n",
       " 22     The best thing about \"The Prey\" is the tag lin...          0\n",
       " 23     A good story, well-acted with unexpected chara...          1\n",
       " 24     A teen-aged girl gets the horse of her dreams ...          1\n",
       " 25     I saw this film because Calexico did the score...          0\n",
       " 26     I was really surprised, that my mom watched wh...          1\n",
       " 27     That's what I kept asking myself during the ma...          0\n",
       " 28     As was mentioned by others, could there be any...          0\n",
       " 29     The Aristorcats is a hilarious film that not m...          1\n",
       " ...                                                  ...        ...\n",
       " 24970  Finally! Third time lucky. This film has been ...          1\n",
       " 24971  Closet Land is an amazing, terrifying piece of...          1\n",
       " 24972  Possibly the finest moment of TV, at least in ...          1\n",
       " 24973  This movie is a real low budget production, ye...          0\n",
       " 24974  Yes, we all know about Dan Schneider's odd lit...          0\n",
       " 24975  Look, I've practically lost all hope in Nickel...          0\n",
       " 24976  The Japanese have probably the most sadistic m...          1\n",
       " 24977  Only in the Hollywood audiovisual fiction worl...          0\n",
       " 24978  Very silly high school/teen flick about geeks ...          0\n",
       " 24979  The story of Farewell to the King is intriguin...          0\n",
       " 24980  I saw this film at a small screening. Even tho...          1\n",
       " 24981  When I saw the poster at the theater, I though...          0\n",
       " 24982  I couldn't believe that the Adult Swim guys ca...          1\n",
       " 24983  i L-O-V-E this movie... everyone and their gra...          1\n",
       " 24984  This started out as a good sketch comedy. The ...          0\n",
       " 24985  Joe was first released in the US in the summer...          0\n",
       " 24986  I speak badly of G.I.J.:T.M. mostly because I ...          0\n",
       " 24987  Hulk Hogan stars as a champion wrestler (A rea...          0\n",
       " 24988  This is hands down the most annoying and frust...          0\n",
       " 24989  This is the first film I've watched from the I...          0\n",
       " 24990  No gore, no blood, no gratifying death scenes....          0\n",
       " 24991  This is one of those wonderful martial-arts mo...          0\n",
       " 24992  This is one of the best action films I have se...          1\n",
       " 24993  Terrible. Absolutely terrible. Long, confusing...          0\n",
       " 24994  this film is basically a poor take on the old ...          0\n",
       " 24995  There I am sitting at home in the morning, sud...          0\n",
       " 24996  Tromeo and Juliet is perhaps the best Shakespe...          1\n",
       " 24997  Im usually wary of movies hovering around the ...          1\n",
       " 24998  Is Thursday an original film? Heck no, but it ...          1\n",
       " 24999  *SPOILERS INCLUDED*<br /><br />Alfred Hitchcoc...          0\n",
       " \n",
       " [25000 rows x 2 columns])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = \"./aclImdb\" #Make sure you put the data folder in the same directory as this jupyter notebook file\n",
    "labeledData = {}\n",
    "for i in [\"train\", \"test\"]:\n",
    "    labeledData[i] = []\n",
    "    for sentiment in [\"pos\", \"neg\"]:\n",
    "        score = 1 if sentiment == \"pos\" else 0\n",
    "        path = os.path.join(directory, i, sentiment)\n",
    "        for filename in os.listdir(path):\n",
    "            with open(os.path.join(path, filename), encoding=\"utf8\") as f:\n",
    "                labeledData[i].append([f.read(), score])  #Initially adds them to separate lists\n",
    "\n",
    "np.random.shuffle(labeledData[\"train\"]) #Shuffling\n",
    "labeledData[\"train\"] = pd.DataFrame(labeledData[\"train\"], columns = ['text', 'sentiment']) #Putting them in a dataframe\n",
    "np.random.shuffle(labeledData[\"test\"])\n",
    "labeledData[\"test\"] = pd.DataFrame(labeledData[\"test\"], columns = ['text', 'sentiment'])\n",
    "labeledData[\"train\"], labeledData[\"test\"] #Prints out both pandas dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer, one_hot, text_to_word_sequence\n",
    "\n",
    "tokenizer = Tokenizer(num_words=6000)\n",
    "tokenizer.fit_on_texts(labeledData[\"train\"][\"text\"])\n",
    "x_train = tokenizer.texts_to_sequences(labeledData[\"train\"][\"text\"])\n",
    "x_test = tokenizer.texts_to_sequences(labeledData[\"test\"][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "max_words = 500\n",
    "x_train_pad = sequence.pad_sequences(x_train, maxlen=max_words)\n",
    "x_test_pad = sequence.pad_sequences(x_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index\n",
    "np.amax(x_train_pad) + 1\n",
    "x_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gensim\n",
    "# from keras.preprocessing.text import Tokenizer, one_hot, text_to_word_sequence\n",
    "\n",
    "# import time\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# stop_words = ['ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', 'further', 'was', 'here', 'than']\n",
    "# stop_words = ['in', 'of', 'at', 'a', 'the']\n",
    "# def tokenize(val):\n",
    "#     ans = text_to_word_sequence(val)\n",
    "#     ans = [a for a in ans if not a in stop_words]\n",
    "#     return ans\n",
    "# reviews = labeledData[\"train\"][\"text\"].append(labeledData[\"test\"][\"text\"], ignore_index=True).values\n",
    "\n",
    "# words = [tokenize(val) for val in reviews.tolist()]\n",
    "\n",
    "# model = gensim.models.Word2Vec(sentences=words, size=50, window = 100, workers = 8, min_count=1, sg = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 100)          600000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                17024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 617,057\n",
      "Trainable params: 617,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "6000\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, GRU, Bidirectional, GlobalMaxPool1D\n",
    "vocab_size = np.amax(x_train_pad) + 1\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_words))\n",
    "\n",
    "model.add(LSTM(32))\n",
    "\n",
    "# model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
    "# model.add(GlobalMaxPool1D())\n",
    "# model.add(Dense(20, activation=\"relu\"))\n",
    "#model.add(Dropout(0.05))\n",
    "\n",
    "#model.add(GRU(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())\n",
    "print(vocab_size)\n",
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model2 = Sequential()\n",
    "#model2.add(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 46s 2ms/step - loss: 0.4665 - acc: 0.7754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25bcd7207b8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_pad, labeledData[\"train\"][\"sentiment\"].values, \n",
    "          batch_size = 128, epochs = 1, #validation_split=0.2\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8596\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test_pad, labeledData[\"test\"][\"sentiment\"], verbose=0)\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 epoch only\n",
    "#0.87552 - 128 batch size .2 validation_split using max value 52 seconds\n",
    "#0.8658 - 128 batch size .2 validation_split using max value 52 seconds\n",
    "#0.87056 145 s using 5000 32 batch size\n",
    "#0.85432 196s using max value 32 batch size\n",
    "#model.\n",
    "\n",
    "#default: 128 batch size 0 validation_splist 32 lstm size acc: .869\n",
    "# #default with dropout layer .874\n",
    "# print(scores)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of model: 0.8596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict(x_test_pad)\n",
    "acc = accuracy_score(labeledData[\"test\"][\"sentiment\"], np.around(y_pred))\n",
    "print(\"Accuracy score of model: \"+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.around(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x25bdc3c0c88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embedding(vocab_size, 100, input_length=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = Sequential()\n",
    "model.layers[0].get_weights()[0].shape\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding([model.layers[0].get_weights()[0]], 100, weights = [model.layers[0].get_weights()[0]], input_length = max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-17-71b4bcc48c83>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-71b4bcc48c83>\"\u001b[1;36m, line \u001b[1;32m12\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def setup_pareto_front(pareto_info, method, func_num, summary_type, gen, trial, auc):\n",
    "# #     combo = sorted(pareto_info, key=lambda x: x[0])\n",
    "# #     pop_1 = [a for a, b in combo]\n",
    "# #     pop_2 = [b for a, b in combo]\n",
    "    \n",
    "#     plt.scatter(pop_1, pop_2, color='g')\n",
    "#     plt.plot(pop_1, pop_2, color='b', drawstyle='steps-post')\n",
    "# #     plt.xlabel(fitness_index_dict[0])\n",
    "# #     plt.ylabel(fitness_index_dict[1])\n",
    "#     plt.title(f\"Evolution Type: {method}\\nFunction: {func_num}\\nBest Pareto Front for gen{gen} trial{trial}\\n{summary_type}auc:{auc}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_pareto_front([(327,342), (341,337.25), (342.25,339.5), (337.25, 348.25), (339.75,348.25), (333, 356), (309.75, 380.25), (356, 336.25), ()] , \"text classification\", \"coolness\", \"idk\", 34, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# with open('movie3.csv', newline='') as lines:\n",
    "#      spamreader = csv.reader(lines, quotechar='\"', delimiter=',',\n",
    "#                      quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "#      for row in spamreader:\n",
    "#         print(row[2:3])\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"movie3.csv\", header = None)\n",
    "df[df.columns[2:4]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(df[2], df[3], color='g')\n",
    "# plt.plot(pop_1, pop_2, color='b', drawstyle='steps-post')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dominates(a, b):\n",
    "    \"\"\"\n",
    "    Test if a dominates b\n",
    "    :param a:\n",
    "    :param b:\n",
    "    :return: boolean\n",
    "    \"\"\"\n",
    "    return np.all(a <= b)\n",
    "\n",
    "def my_pareto(data):\n",
    "    pareto_points = []\n",
    "    for i, x in enumerate(data):\n",
    "        pareto_status = True\n",
    "        pareto_points_to_remove = []\n",
    "        for j in pareto_points:\n",
    "            # If a pareto point dominates our point, we already know we are not pareto\n",
    "            if dominates(data[j], x):\n",
    "                pareto_status = False\n",
    "                break\n",
    "            # If our point dominates a Pareto point, that point is no longer Pareto\n",
    "            if dominates(x, data[j]):\n",
    "                pareto_points_to_remove.append(j)\n",
    "        # Remove elements by value\n",
    "        for non_pareto_point in pareto_points_to_remove:\n",
    "            pareto_points.remove(non_pareto_point)\n",
    "        if pareto_status:\n",
    "            pareto_points.append(i)\n",
    "    return pareto_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "list = my_pareto(df[df.columns[2:4]].values)\n",
    "df = df.iloc[list]\n",
    "df = df.sort_values(by=[2])\n",
    "df = df.iloc[9:30-7]\n",
    "pop1 = df[2]\n",
    "pop2 = df[3]\n",
    "plt.scatter(pop1, pop2, s = 20, color='g')\n",
    "plt.plot(pop1, pop2, color='b', drawstyle='steps-post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "st = [\"TfidfVectorizer with Single Learner MultiNB\", \n",
    "\"TfidfVectorizer with Single Learner MultiNB\", \n",
    "      \"TfidfVectorizer with Single Learner MultiNB\", \n",
    "       \"TfidfVectorizer with Single Learner MultiNB\", \n",
    "       \"CountVectorizer with Single Learner MultiNB\", \n",
    "       \"CountVectorizer with Single Learner MultiNB\", \n",
    "       \"TfidfVectorizer with Bagged Learner Passive\", \n",
    "\"TfidfVectorizer with Single Learner LinSVC\",\n",
    " \"TfidfVectorizer and Grid Search Learner SGD\", \n",
    " \"TfidfVectorizer and Single Learner Passive\",\n",
    " \"TfidfVectorizer and Bagged Learner Passive\", \n",
    " \"Tfidf and Single Learner Passive\", \n",
    " \"Tfidf and Single Learner Passive\", \n",
    "      \"Tfidf and Single Learner Passive\" ]\n",
    "\n",
    "\n",
    "colors = ['g','g', 'g', 'g', 'lime', 'lime', 'lightcoral', 'y', 'k', 'r', 'lightcoral', 'r', 'r', 'r']\n",
    "plt.title('Pareto Front for Optimal Individuals in IMDB Dataset')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"False Negative Rate\")\n",
    "falsePos = (df[2]/6249).values\n",
    "falseNeg = (df[3]/6249).values\n",
    "\n",
    "for i in range(len(df)):\n",
    "    stt = st[i]\n",
    "    pop1 = falsePos[i]\n",
    "    pop2 = falseNeg[i]\n",
    "    plt.scatter(pop1, pop2, s = 40, color=colors[i], label = colors[i],)\n",
    "    #plt.text(pop1+.05, pop2+.05, stt, fontsize=9)\n",
    "popp1 = falsePos\n",
    "popp2 = falseNeg\n",
    "plt.xlim([.030, .06])\n",
    "plt.plot(popp1, popp2, color='b', drawstyle='steps-post', linewidth = 1)\n",
    "\n",
    "falseNeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_elements = [\n",
    "                   Line2D([0], [0], marker='o', color='w', label='TfidfVectorizer with Single Learner MultiNB',\n",
    "                          markerfacecolor='g', markersize=8),\n",
    "     Line2D([0], [0], marker='o', color='w', label='CountVectorizer with Single Learner MultiNB',\n",
    "                          markerfacecolor='lime', markersize=8),\n",
    "     Line2D([0], [0], marker='o', color='w', label='TfidfVectorizer with Bagged Learner Passive',\n",
    "                          markerfacecolor='lightcoral', markersize=8),\n",
    "     Line2D([0], [0], marker='o', color='w', label='TfidfVectorizer with Single Learner LinSVC',\n",
    "                          markerfacecolor='y', markersize=8),\n",
    "     Line2D([0], [0], marker='o', color='w', label='TfidfVectorizer with Grid Search Learner SGD',\n",
    "                          markerfacecolor='g', markersize=8),\n",
    "     Line2D([0], [0], marker='o', color='w', label='TfidfVectorizer with Single Learner Passive',\n",
    "                          markerfacecolor='r', markersize=8)\n",
    "]\n",
    "fig, ax = plt.subplots()\n",
    "ax.legend(handles=legend_elements, loc = 'center')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = 0\n",
    "for val in df.iloc[:,1]:\n",
    "    print(o, val)\n",
    "    print()\n",
    "    o+=1\n",
    "\n",
    "st = [\"TfidfVectorizer with Single Learner MultiNB\", \n",
    "\"TfidfVectorizer with Single Learner MultiNB\", \n",
    "      \"TfidfVectorizer with Single Learner MultiNB\", \n",
    "       \"TfidfVectorizer with Single Learner MultiNB\", \n",
    "       \"CountVectorizer with Single Learner MultiNB\", \n",
    "       \"CountVectorizer with Single Learner MultiNB\", \n",
    "       \"TfidfVectorizer with Bagged Learner Passive\", \n",
    "\"Tfidf with Single Learner LinSVC\",\n",
    " \"Tfidf and Grid Search Learner SGD\", \n",
    " \"Tfidf and Bagged Learner Passive C: 0.1\",\n",
    " \"Tfidf and Single Learner Passive C: 0.01\", \n",
    " \"Tfidf and Single Learner Passive C: 1 stop_word list: default\", \n",
    " \"Tfidf and Single Learner Passive C: 1 stop_word list: None\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"movie3.csv\", header = None)\n",
    "list = my_pareto(df2[df2.columns[2:4]].values)\n",
    "df2 = df2.iloc[list]\n",
    "df2 = df2.sort_values(by=[2])\n",
    "df2.iloc[24, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
