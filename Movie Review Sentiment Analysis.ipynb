{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Movie Review Sentiment Analysis.ipynb","version":"0.3.2","provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"vS-inlehw6mj","colab_type":"code","colab":{}},"source":["#All the necessary imports\n","import numpy as np\n","import nltk\n","import pandas as pd\n","import os\n","import re"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4bLpOvq3w6mm","colab_type":"text"},"source":["### This is an example of a movie review."]},{"cell_type":"code","metadata":{"id":"ujkLbzInw6mm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":180},"outputId":"dad859d9-0e42-4faf-b27a-3dc2acb29559","executionInfo":{"status":"error","timestamp":1559673169276,"user_tz":240,"elapsed":2087,"user":{"displayName":"Mohan Dodda","photoUrl":"","userId":"17351605233442423714"}}},"source":["f = open('./aclImdb/train/pos/10327_7.txt', encoding=\"utf8\")\n","print(f.read())"],"execution_count":2,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-8ca680e826a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./aclImdb/train/pos/10327_7.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './aclImdb/train/pos/10327_7.txt'"]}]},{"cell_type":"markdown","metadata":{"id":"g6CLSYD9w6mq","colab_type":"text"},"source":["#### Putting the train and test data into a pandas dataframe. It shuffles the data as well."]},{"cell_type":"code","metadata":{"id":"ynsZuwjaw6mq","colab_type":"code","colab":{}},"source":["directory = \"./aclImdb\" #Make sure you put the data folder in the same directory as this jupyter notebook file\n","labeledData = {}\n","for i in [\"train\", \"test\"]:\n","    labeledData[i] = []\n","    for sentiment in [\"pos\", \"neg\"]:\n","        score = 1 if sentiment == \"pos\" else 0\n","        path = os.path.join(directory, i, sentiment)\n","        for filename in os.listdir(path):\n","            with open(os.path.join(path, filename), encoding=\"utf8\") as f:\n","                labeledData[i].append([f.read(), score])  #Initially adds them to separate lists\n","\n","np.random.shuffle(labeledData[\"train\"]) #Shuffling\n","labeledData[\"train\"] = pd.DataFrame(labeledData[\"train\"], columns = ['text', 'sentiment']) #Putting them in a dataframe\n","np.random.shuffle(labeledData[\"test\"])\n","labeledData[\"test\"] = pd.DataFrame(labeledData[\"test\"], columns = ['text', 'sentiment'])\n","labeledData[\"train\"], labeledData[\"test\"] #Prints out both pandas dataframes"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3AA4Zc3pw6ms","colab_type":"text"},"source":["The first column contains the movie reviews in separated rows.\n","The second column indicates whether the review is a positive or negative review. \n","A positive reivew has 7-10 stars, A negative review has 1-4 stars. 5-6 stars are disregarded"]},{"cell_type":"code","metadata":{"id":"PmVBzAvhw6mt","colab_type":"code","colab":{}},"source":["labeledData[\"train\"] "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kGyvjiu4w6mw","colab_type":"code","colab":{}},"source":["labeledData[\"train\"][\"text\"][0]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BZMXwyNiw6mz","colab_type":"text"},"source":["## Converting the movie reviews into Specific Bag of Words Vectors"]},{"cell_type":"code","metadata":{"id":"BQAKtkfVw6mz","colab_type":"code","colab":{}},"source":["#sklearn imports\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics import accuracy_score\n","from sklearn.svm import LinearSVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.naive_bayes import MultinomialNB\n","\n","#Stop word list created to be used\n","stop_words = ['in', 'of', 'at', 'a', 'the', 'and']\n","\n","#how each review will be vectorized\n","vectorizer = CountVectorizer(stop_words=stop_words, #These stop words are removed\n","                             binary=True, # if it contains in list it's 1, else it is 0\n","                             ngram_range=(1,2) #contains pairs of words as well\n","                            )\n","\n","x_train = vectorizer.fit_transform(labeledData[\"train\"][\"text\"]) #reviews from train dataframe are vectorized\n","x_test = vectorizer.transform(labeledData[\"test\"][\"text\"])  #reviews from test dataframe are vectorized\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sk6b9UGpw6m1","colab_type":"text"},"source":["## Creating a model, training, and applying the model"]},{"cell_type":"code","metadata":{"id":"6jTPFlBow6m2","colab_type":"code","colab":{}},"source":["#Any linear model can be used\n","model = LinearSVC(C=.01)  \n","#This is another model that can be used\n","model2 = LogisticRegression()   \n","#model trained associating review vectors to it sentiment scores \n","model.fit(x_train, labeledData[\"train\"][\"sentiment\"]) \n","#applying model on test data creates what model thinks is sentiment scores associated with each movie review\n","y_pred = model.predict(x_test) \n","#accuracy score created by comparing to actual sentiment score to model's predicted sentiment score\n","acc = accuracy_score(labeledData[\"test\"][\"sentiment\"], y_pred)\n","print(\"Accuracy score of model: \"+str(acc))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NAmrxbPIw6m4","colab_type":"text"},"source":["#This is a the representation of the matrix of all the vectorized movie reviews. \n","#The data is very sparse, so this data only shows the position on if a word is contained in a movie review\n","#The first number in the ordered pair represents the movie review. \n","#The second number in the ordered pair represents a particular word.\n","#The row of 1 shows that it is the word is there in the movie review.\n","#Everthing else are 0s"]},{"cell_type":"code","metadata":{"id":"iUd5pls4w6m4","colab_type":"code","colab":{}},"source":["print(x_train)\n","#x_train[0].nonzero()[1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EisPtJTBw6m6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"zwLr52c3w6m9","colab_type":"code","colab":{}},"source":["#This prints out the first 10 n-grams associated with the first review above and the correspoding indeces for each n-gram\n","count = 10;\n","for i in x_train[0].nonzero()[1]:\n","    print(str(i)+\": \" + vectorizer.get_feature_names()[i])\n","    count-=1\n","    if (count == 0):\n","        break"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_TkJyWUdw6m_","colab_type":"text"},"source":["## Using pipeline to make it easier (puts, vectorizer and model in one line)\n","Using Tfidf by transforming original countvectorizer using Tfidf"]},{"cell_type":"code","metadata":{"id":"GvXM0pqxw6m_","colab_type":"code","colab":{}},"source":["from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.preprocessing import FunctionTransformer\n","from sklearn.ensemble import RandomForestClassifier\n","#pipe = Pipeline([('vect', CountVectorizer(binary=True, ngram_range=(1,2))),('clf',LogisticRegression(C=.05))])fg\n","stop_words = ['in', 'of', 'at', 'a', 'the']\n","\n","##pipe = Pipeline([('vect', CountVectorizer(binary=True, ngram_range=(1,2), stop_words=stop_words)), ('clf',LinearSVC(C=.01))])##\n","\n","#Making pipeline. has vectorizer, uses tfidf, and uses multinomialnb for the model\n","pipe = Pipeline([('vect', CountVectorizer(binary=True, ngram_range=(1,2), stop_words=stop_words)), \n","                 ('tfid', TfidfTransformer()), ('clf', MultinomialNB())])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"97GuDIQkw6nB","colab_type":"code","colab":{}},"source":["#fits whole pipeline using the train text as x value and train sentiment as y value and makes model\n","pipe.fit(labeledData[\"train\"][\"text\"], labeledData[\"train\"][\"sentiment\"]) \n","#model predicts sentiment scores using test dataframe\n","y_pred = pipe.predict(labeledData[\"test\"][\"text\"])\n","#compares model sentiment scores to actual sentiment scores\n","acc = accuracy_score(labeledData[\"test\"][\"sentiment\"], y_pred)\n","print(\"Accuracy score of the model: \"+ str(acc))"],"execution_count":0,"outputs":[]}]}